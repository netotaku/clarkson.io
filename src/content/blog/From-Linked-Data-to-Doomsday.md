---
title: From Linked Data to Doomsday
description: Why we keep mistaking developer tools for civilisation shifts
pubDate: 'May 17 2025'
heroImage: '/images/zombies.jpg'
cta: "I help teams and individuals navigate new technology without falling for the pitch. Whether it’s AI, ethical tracking, or a better CMS — I help you build what actually works."
---
AI isn’t just the next big thing — if you believe the headlines, it’s the end of work, the end of truth, or the end of the world. That’s quite the arc for what is, at its core, a probabilistic text prediction engine.

But this pattern isn’t new. Every few years, we watch a relatively modest developer convenience get repackaged as a civilisation-shifting revolution. The semantic web was going to restructure human knowledge. Blockchain was going to replace governments. WebAssembly was going to kill off native apps. Now LLMs are going to out-think us, out-create us, and possibly enslave us.

What’s going on here? Why do these tools, which often solve very real problems for developers, get inflated into cultural or political tipping points? And do large language models — finally — live up to the hype?

## The pattern: Convenience mistaken for revolution

Technologists love to abstract. That’s what makes the work so satisfying. But abstraction has a downside: we mistake what something *does* for what it *means*.

A developer convenience — like a better way to structure web data, or a new model of digital identity — gets wrapped in grand language. We don’t just say, “This makes things easier.” We say, “This will change everything.”

Then the media joins in. Add a couple of TED talks, some VC money, and a slogan about democratising something — and suddenly what started as a backend fix is now “the future of the internet”.

## A short history of long promises

### **Linked Data**  
  The idea was elegant: structure the web so that machines could understand relationships between things. It made sense in academia and open data circles, but outside of those? Too complex, too brittle, too niche. The web we got is still mostly for humans.

### **Blockchain**  
  A decentralised ledger is genuinely useful in some contexts. But it’s been sold as a fix for everything from corruption to copyright. The reality? Mostly used for speculation and scams. Yes, it's meaningful — but not remotely as government-toppling as promised.

### **Cryptocurrency**  
  A truly novel idea: digital, decentralised money with no central authority. It’s here to stay, and it works — but it hasn’t transformed the global banking system. Instead, it’s created a parallel one, with its own institutions, exchanges, fraud, and power players. Revolutionary in architecture, but not in outcome.

### **NFTs**  
  Meant to redefine digital ownership. Instead, we got expensive monkey pictures and hype-fuelled collectibles. Technically clever, culturally empty — a solution in search of a problem, marketed like a movement.

### **VR and the Metaverse**  
  Sold as inevitable. In practice: clunky, isolating, expensive, and often unwanted. The idea was right — immersive digital spaces are compelling. But the execution (and the hype) got ahead of the desire.

### **NoSQL, GraphQL, WebAssembly, PWAs...**  
  All valuable tools. None of them tore down the old world. They just made parts of it work better.

## What’s different about LLMs?

For the first time in years, we’re dealing with a tool that’s not just useful to developers — it’s useful to *everyone*. That changes the game.

- Writers use them for drafts and research.  
- Developers use them to prototype and debug.  
- Businesses use them for customer support, training, and automation.

They’re incredibly general-purpose. That’s rare. But they’re also profoundly misunderstood.

An LLM doesn’t *understand* language. It isn’t thinking. It’s pattern-matching at scale, based on enormous amounts of data. It’s clever compression — not cognition.

So no, it’s not sentient. It won’t kill us. But it *will* change how we work — because we’re finding ways to adapt it to thousands of small, practical tasks.

## When the pitch gets apocalyptic

There’s a well-worn arc to tech hype:
1. A useful tool is discovered.
2. Developers adopt it enthusiastically.
3. Investors smell scale.
4. Media sells the extremes: utopia or doomsday.
5. Public confusion sets in.

With AI, we’ve just skipped straight to step 4.

There’s talk of it destroying jobs, rewriting laws, ending democracy. Some of that concern is valid — not because the tech is evil, but because the people deploying it are incentivised to disrupt without accountability.

But that’s not new either. We didn’t need general AI to automate inequality or optimise for profit at the expense of people. Capitalism’s been doing just fine without it.

## What actually changes the world

The tools that truly shift culture aren’t usually the ones that dominate the headlines. They’re the ones that quietly change what people can *do*.

Think about:
- **HTML**: Gave structure to a chaotic internet and made it accessible to anyone with a text editor.
- **Email**: Quietly replaced post and fax without fanfare — now unavoidable.
- **SMS**: Connected billions with a 160-character limit.
- **Google Search**: Changed how we retrieve knowledge.
- **APIs**: Created new business models by letting systems talk to each other.
- **SQL and relational databases**: Still underpin almost everything — from banks to blogs — without ever being called “the future”.
- **The internet itself**: Once predicted to be a passing fad.

And yes, that really happened — a *Daily Mail* article in December 2000 cited a report claiming the internet “may be just a passing fad” as “millions give up on it” due to boredom and alienation. Not the Mail’s finest hour — and not an uncommon sentiment at the time. And yet, here we are.

LLMs might follow that same route. Not as overlords or oracles, but as autocomplete systems we build into everything — interfaces, workflows, documentation, education. They're not a revolution. They’re a multiplier.

And that's more than enough.
